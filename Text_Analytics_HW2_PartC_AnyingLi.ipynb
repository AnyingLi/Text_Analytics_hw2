{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['text', 'clf']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeanthea/anaconda/envs/dato-env/lib/python2.7/site-packages/IPython/kernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "yelp = pd.read_csv('Yelp.csv')\n",
    "\n",
    "yelp['rating'] = 0\n",
    "\n",
    "mask= yelp['stars']>3\n",
    "\n",
    "yelp['rating'][mask] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedShuffleSplit \n",
    "\n",
    "thousand = yelp[:1000]\n",
    "\n",
    "y = thousand['rating']\n",
    "\n",
    "X = thousand.drop(['stars','Review','rating'], axis=1)\n",
    "\n",
    "Review = thousand['Review']\n",
    "\n",
    "### we need a test set that we didn't train on to find the best weights for combining the classifiers\n",
    "sss = StratifiedShuffleSplit(y, test_size=0.3, random_state=1234)\n",
    "for train_index, test_index in sss:\n",
    "    break\n",
    "\n",
    "train_x, train_y,train_review = X.values[train_index],y.values[train_index],Review[train_index]\n",
    "test_x, test_y, test_review = X.values[test_index], y.values[test_index],Review[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import operator\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "import re\n",
    "import string\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def lemmatize(tokens,wnl):\n",
    "    lem=[]\n",
    "    for item in tokens:\n",
    "        lem.append(wnl.lemmatize(item))\n",
    "    return lem\n",
    "\n",
    "def my_tokenizer(text):\n",
    "    text = \"\".join([ch for ch in text if ch not in string.punctuation])\n",
    "    text = re.sub('[0-9]+','',text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    #result = stem_tokens(tokens, stemmer)\n",
    "    #result = lemmatize(tokens, wnl)\n",
    "    result = tokens\n",
    "    return result\n",
    "    \n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=3,max_df=0.9,tokenizer=my_tokenizer,\n",
    " ngram_range=(1, 2), \n",
    " stop_words='english',\n",
    " strip_accents='unicode',max_features=200)\n",
    "\n",
    "text_1 = vectorizer.fit_transform(train_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: Multinomial Naive Bayes\n",
      "\n",
      "The precision for this classifier is 0.740484429066\n",
      "The recall for this classifier is 1.0\n",
      "The f1 for this classifier is 0.850894632207\n",
      "The accuracy for this classifier is 0.75\n"
     ]
    }
   ],
   "source": [
    "from nltk import NaiveBayesClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "text_2 = vectorizer.transform(test_review)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb =  MultinomialNB().fit(text_1, train_y)\n",
    "\n",
    "y_nb_predicted = nb.predict(text_2)\n",
    "\n",
    "\n",
    "print \"MODEL: Multinomial Naive Bayes\\n\"\n",
    "\n",
    "print 'The precision for this classifier is ' + str(metrics.precision_score(test_y, y_nb_predicted))\n",
    "print 'The recall for this classifier is ' + str(metrics.recall_score(test_y, y_nb_predicted))\n",
    "print 'The f1 for this classifier is ' + str(metrics.f1_score(test_y, y_nb_predicted))\n",
    "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(test_y, y_nb_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The top 50 most informative features: \n",
      "spicy,sauce,patio,meal,tiki,eat,phoenix,potato,shrimp,order,dinner,pork,amazing,tasty,fries,excellent,atmosphere,friendly,ordered,rice,went,favorite,definitely,lunch,awesome,fish,happy hour,best,nice,restaurant,drinks,menu,little,sweet,got,hour,try,happy,delicious,love,time,chicken,service,really,hula,like,good,place,food,great\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from operator import itemgetter\n",
    "\n",
    "N = 50\n",
    "vocabulary = np.array([t for t, i in sorted(vectorizer.vocabulary_.iteritems(), key=itemgetter(1))])\n",
    "\n",
    "topN = np.argsort(nb.coef_[0])[-N:]\n",
    "\n",
    "print \"\\nThe top %d most informative features: \\n%s\" % (N, ','.join(vocabulary[topN]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_informative = vocabulary[topN]\n",
    "\n",
    "for w in most_informative:\n",
    "    X[w]= 0\n",
    "\n",
    "def create_features(tokens,i):\n",
    "    document_words = set(tokens)\n",
    "    features = {}\n",
    "    for word in most_informative:\n",
    "        if word in document_words:\n",
    "            X.loc[i,word] = 1\n",
    "        #features['contains({})'.format(word)] = (word in document_words)\n",
    "    #return features   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "      <th>Cheap</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Expensive</th>\n",
       "      <th>VeryExpensive</th>\n",
       "      <th>American</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>French</th>\n",
       "      <th>...</th>\n",
       "      <th>time</th>\n",
       "      <th>chicken</th>\n",
       "      <th>service</th>\n",
       "      <th>really</th>\n",
       "      <th>hula</th>\n",
       "      <th>like</th>\n",
       "      <th>good</th>\n",
       "      <th>place</th>\n",
       "      <th>food</th>\n",
       "      <th>great</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   votes_cool  votes_funny  votes_useful  Cheap  Moderate  Expensive  \\\n",
       "0           0            0             0      1         0          0   \n",
       "1           2            2             2      1         0          0   \n",
       "2           0            0             1      1         0          0   \n",
       "3           0            1             2      1         0          0   \n",
       "4           7            9             9      1         0          0   \n",
       "\n",
       "   VeryExpensive  American  Chinese  French  ...    time  chicken  service  \\\n",
       "0              0         0        0       0  ...       0        0        0   \n",
       "1              0         0        0       0  ...       0        0        0   \n",
       "2              0         0        0       0  ...       0        0        0   \n",
       "3              0         0        0       0  ...       0        0        0   \n",
       "4              0         0        0       0  ...       0        0        0   \n",
       "\n",
       "   really  hula  like  good  place  food  great  \n",
       "0       0     0     0     0      0     0      0  \n",
       "1       0     0     0     0      0     0      0  \n",
       "2       0     0     0     0      0     0      0  \n",
       "3       0     0     0     0      0     0      0  \n",
       "4       0     0     0     0      0     0      0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    text = \"\".join([ch for ch in Review[i] if ch not in string.punctuation])\n",
    "    text = re.sub('[0-9]+','',text)\n",
    "    tokens = nltk.word_tokenize(text.lower().decode('utf-8'))\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    feature = create_features(tokens,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "      <th>Cheap</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Expensive</th>\n",
       "      <th>VeryExpensive</th>\n",
       "      <th>American</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>French</th>\n",
       "      <th>...</th>\n",
       "      <th>time</th>\n",
       "      <th>chicken</th>\n",
       "      <th>service</th>\n",
       "      <th>really</th>\n",
       "      <th>hula</th>\n",
       "      <th>like</th>\n",
       "      <th>good</th>\n",
       "      <th>place</th>\n",
       "      <th>food</th>\n",
       "      <th>great</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   votes_cool  votes_funny  votes_useful  Cheap  Moderate  Expensive  \\\n",
       "0           0            0             0      1         0          0   \n",
       "1           2            2             2      1         0          0   \n",
       "2           0            0             1      1         0          0   \n",
       "3           0            1             2      1         0          0   \n",
       "4           7            9             9      1         0          0   \n",
       "\n",
       "   VeryExpensive  American  Chinese  French  ...    time  chicken  service  \\\n",
       "0              0         0        0       0  ...       0        0        0   \n",
       "1              0         0        0       0  ...       0        0        1   \n",
       "2              0         0        0       0  ...       0        0        1   \n",
       "3              0         0        0       0  ...       0        0        0   \n",
       "4              0         0        0       0  ...       0        0        0   \n",
       "\n",
       "   really  hula  like  good  place  food  great  \n",
       "0       0     0     0     0      0     0      0  \n",
       "1       0     0     0     1      0     1      0  \n",
       "2       0     0     0     1      0     0      0  \n",
       "3       1     0     0     1      1     1      0  \n",
       "4       0     0     0     1      1     0      0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: Multinomial Naive Bayes\n",
      "\n",
      "The precision for this classifier is 0.775933609959\n",
      "The recall for this classifier is 0.873831775701\n",
      "The f1 for this classifier is 0.821978021978\n",
      "The accuracy for this classifier is 0.73\n"
     ]
    }
   ],
   "source": [
    "nb_text =  MultinomialNB().fit(X.values[train_index], train_y)\n",
    "\n",
    "text_predicted = nb_text.predict(X.values[test_index])\n",
    "\n",
    "\n",
    "print \"MODEL: Multinomial Naive Bayes\\n\"\n",
    "\n",
    "print 'The precision for this classifier is ' + str(metrics.precision_score(test_y, text_predicted))\n",
    "print 'The recall for this classifier is ' + str(metrics.recall_score(test_y, text_predicted))\n",
    "print 'The f1 for this classifier is ' + str(metrics.f1_score(test_y, text_predicted))\n",
    "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(test_y, text_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for this classifier is 0.73\n",
      "The accuracy for this classifier is 0.76\n",
      "The accuracy for this classifier is 0.746666666667\n",
      "Brier scores: (the smaller the better)\n",
      "No calibration: 0.172\n",
      "With isotonic calibration: 0.169\n",
      "With sigmoid calibration: 0.168\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(y.shape[0])\n",
    "\n",
    "sw_train, sw_test = sample_weight[train_index], sample_weight[test_index]\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "\n",
    "clf = MultinomialNB()\n",
    "model_original = clf.fit(X.values[train_index], train_y)  # GaussianNB itself does not support sample-weights\n",
    "prob_pos_clf = clf.predict_proba(X.values[test_index])[:, 1]\n",
    "clf_predicted =model_original.predict(X.values[test_index])\n",
    "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(test_y, clf_predicted))\n",
    "\n",
    "# Naive-Bayes with isotonic calibration\n",
    "clf_isotonic = CalibratedClassifierCV(clf, cv=10, method='isotonic')\n",
    "model_isotonic = clf_isotonic.fit(X.values[train_index], train_y, sw_train)\n",
    "prob_pos_isotonic = clf_isotonic.predict_proba(X.values[test_index])[:, 1]\n",
    "isotonic_predicted = model_isotonic.predict(X.values[test_index])\n",
    "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(test_y, isotonic_predicted))\n",
    "\n",
    "# Naive-Bayes with sigmoid calibration\n",
    "clf_sigmoid = CalibratedClassifierCV(clf, cv=10, method='sigmoid')\n",
    "model_sigmoid  = clf_sigmoid.fit(X.values[train_index], train_y, sw_train)\n",
    "prob_pos_sigmoid = clf_sigmoid.predict_proba(X.values[test_index])[:, 1]\n",
    "sigmoid_predicted = model_sigmoid.predict(X.values[test_index])\n",
    "print 'The accuracy for this classifier is ' + str(metrics.accuracy_score(test_y, sigmoid_predicted))\n",
    "\n",
    "print(\"Brier scores: (the smaller the better)\")\n",
    "\n",
    "clf_score = brier_score_loss(test_y, prob_pos_clf, sw_test)\n",
    "print(\"No calibration: %1.3f\" % clf_score)\n",
    "\n",
    "clf_isotonic_score = brier_score_loss(test_y, prob_pos_isotonic, sw_test)\n",
    "print(\"With isotonic calibration: %1.3f\" % clf_isotonic_score)\n",
    "\n",
    "clf_sigmoid_score = brier_score_loss(test_y, prob_pos_sigmoid, sw_test)\n",
    "print(\"With sigmoid calibration: %1.3f\" % clf_sigmoid_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
